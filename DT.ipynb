{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "train, test = \"data/df_train.csv\", \"data/df_test.csv\"\n",
    "train = np.loadtxt(train, skiprows=1, delimiter=\",\")\n",
    "test = np.loadtxt(test, skiprows=1, delimiter=\",\")\n",
    "_labels = set(train[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CART Cost and Gini functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gini(left_data, right_data, labels):\n",
    "    # This function calculates the total CART cost function for a particular left-right split (p. 221 in Hands-on ML).\n",
    "    # For the left and right subset, we compute the Gini index (the impurity), multiply it by the fraction of instances\n",
    "    # in that particular subset, and then sum the two values together.\n",
    "    \n",
    "        # Creates a list of the classes\n",
    "        classes = labels\n",
    "        \n",
    "        # N amount of instances in parent node\n",
    "        N = len(left_data[:,-1]) + len(right_data[:,-1])\n",
    "    \n",
    "        # Puts the two subsets in a list\n",
    "        datas = [left_data, right_data]\n",
    "        \n",
    "        # Initialize the CART cost function\n",
    "        G = 0\n",
    "        \n",
    "        # Iterate over the two subsets\n",
    "        for data in datas:\n",
    "            # Initializes impurity (gini index) for subset\n",
    "            impurity = 0\n",
    "            # M amount of instances in this subset\n",
    "            M = len(data[:,-1])\n",
    "\n",
    "            # Computes the impurity for the subset. Formula: G_index = sum(pk * (1 â€“ pk))\n",
    "            # Note: The sum is over each class and pk is the fraction of that class in the subset\n",
    "            for i in classes:\n",
    "                # Finds the fraction of instances of the particular class in the subset\n",
    "                x = data[data[:,-1] == i][:,-1]\n",
    "                pk = len(x) / M\n",
    "                impurity += pk * (1 - pk)\n",
    "            \n",
    "            # Adds fraction of nodes in subset multiplied by the subset impurity to the final CART cost function\n",
    "            G += M/N * impurity\n",
    "        return G\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testGini(data, min_sample_leaf):\n",
    "    if len(data[:,-1]) <= min_sample_leaf:\n",
    "        return False\n",
    "    \n",
    "    # Initialize the minimum gini index & the row and column indexes which achieved that value\n",
    "    minimum_gini = 2\n",
    "    minimum_gini_indexes = [None, None]\n",
    "\n",
    "    # Iterates over each feature in the data (each column except last)\n",
    "    for i in range(len(data[0,:-1])):\n",
    "\n",
    "        # Iterates over each row & tries to split the data on that particular value\n",
    "        # Tests Gini index on that split and compares it to minimum_gini\n",
    "        for j in range(len(data[:,i])):\n",
    "            \n",
    "            # This skips the largest value in the feature, so we get N-1 splits\n",
    "            # Avoids zero division in Gini function\n",
    "            if data[j,i] == np.amax(data[:,i]):\n",
    "                continue\n",
    "\n",
    "            # Creates a mask that selects all values\n",
    "            # that are less than or equal to the particular row and column value\n",
    "            # We test if this is the best split\n",
    "            mask = data[:,i] <= data[j,i]\n",
    "\n",
    "            # Makes the left-right split in data that we want to test\n",
    "            left_data = data[:,:][mask]\n",
    "            right_data = data[:,:][~mask]\n",
    "\n",
    "            \"\"\"\n",
    "            print(\"Searching for values smaller than or equal to\", j)\n",
    "            print(train[:,i][mask])\n",
    "            print(\"-\")\n",
    "            print(\"And here's all the column for that condition:\")\n",
    "            print(train[:,:][mask])\n",
    "            print(\"-\")\"\"\"\n",
    "            \n",
    "            \"\"\"\n",
    "            print(\"\\n\")\n",
    "            print(\"Finding cost function of data:\")\n",
    "            print(\"The split condition\")\n",
    "            print(train[j,i])\n",
    "            print(\"left\")\n",
    "            print(left_data)\n",
    "            print(\"right\")\n",
    "            print(right_data)\"\"\"\n",
    "            \n",
    "            \"\"\"# Stopping criterion\n",
    "            # The first is the minimum number of elements in the leaf node & the second is the gini minimum\n",
    "            stopping_criterion = [4, 0.1]\n",
    "            \n",
    "            # Check for first criterion\n",
    "            if len(data_masked) >= stopping_criterion[0]:\"\"\"\n",
    "            \n",
    "            # Tests the Cost Function for the particular split\n",
    "            G = Gini(left_data, right_data,_labels)\n",
    "            #print(G)\n",
    "                \n",
    "            # Checks if new gini minimum   ////  & second criterion ////\n",
    "            # If true, changes minimum_gini and minimum_gini_indexes\n",
    "            if G < minimum_gini: # and G >= stopping_criterion[1]:\n",
    "                #print(\"True\")\n",
    "                #print(minimum_gini)\n",
    "                minimum_gini = G\n",
    "                #print(minimum_gini)\n",
    "                minimum_gini_indexes = [j, i]\n",
    "        \n",
    "    # returns the minimum gini index & the corresponding indexes\n",
    "    return minimum_gini, minimum_gini_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6199065196548418, [47, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing field -- Output of Gini function\n",
    "testGini(train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06, 0.09, 0.14, 0.15, 0.27, 0.53, 0.54, 0.56, 0.61, 0.64, 0.66, 0.69, 1.06, 1.19, 1.38, 1.55, 1.57, 1.57, 1.59, 1.63, 1.67, 1.68, 1.71, 2.2, 2.88, 3.15]\n"
     ]
    }
   ],
   "source": [
    "# Testing field\n",
    "print(train[47,7])\n",
    "print(sorted(train[:,7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Algorithm\n",
    "\n",
    "#### DT and Node classes that call functions above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    # Initializes new node\n",
    "    def __init__(self, data, min_sample_split, max_depth, node_depth):\n",
    "        # Initializes attributes\n",
    "        self.data = data # subset of data on Node\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.class_predict = None\n",
    "        self.min_sample_split = min_sample_split # Stop condition\n",
    "        self.max_depth = max_depth\n",
    "        self.node_depth = node_depth\n",
    "        \n",
    "        #print(\"Depth of node: \", self.node_depth)\n",
    "        \n",
    "        ### STOP CONDITIONS - BECOMES LEAF NODE ###\n",
    "        # & then decide class (based on most frequent class in Node) \n",
    "        # If Node data length smaller than minimum sample for a leaf OR if node_depth equal to max_depth\n",
    "\n",
    "        if (len(self.data[:,-1]) <= self.min_sample_split) or (self.node_depth == self.max_depth) or (len(set(self.data[:,-1])) == 1):\n",
    "            self.counts = np.bincount(self.data[:,-1].astype(int))\n",
    "            self.class_predict = np.argmax(self.counts)\n",
    "            \n",
    "            #print(\"Node ready to predict! Class:\", self.class_predict)\n",
    "        \n",
    "        else:\n",
    "            self.minimum_gini, self.minimum_gini_indexes = testGini(data, self.min_sample_split)\n",
    "            self.j, self.i = self.minimum_gini_indexes[0], self.minimum_gini_indexes[1]\n",
    "            self.split_value = self.data[self.j, self.i]\n",
    "            self.mask = self.data[:,self.i] <= self.split_value\n",
    "            self.left_data, self.right_data = self.data[self.mask], self.data[~self.mask]\n",
    "            \n",
    "            \"\"\"print(\"Left data:\")\n",
    "            print(self.left_data)\n",
    "            print(\"Right data:\")\n",
    "            print(self.right_data)\n",
    "            print(\"\\n\")\"\"\"\n",
    "            \n",
    "        #print(\"true\")\n",
    "\n",
    "class DecisionTree():\n",
    "    def __init__(self, min_sample_split, max_depth): \n",
    "        # Initializes empty Decision Tree\n",
    "        self.root = None  # root of DT\n",
    "        self.count = 0\n",
    "        self.tree_depth = []\n",
    "        \n",
    "        # Pre-pruning\n",
    "        self.min_sample_split = min_sample_split  \n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def insert(self, data):\n",
    "        # Inserts root node or calls other function\n",
    "        if not self.root:\n",
    "            self.root = Node(data, self.min_sample_split, self.max_depth, 0)\n",
    "            \n",
    "            \"\"\"print(\"Root data, left - right\")\n",
    "            print(self.root.left_data[:,-1])\n",
    "            print(\"-\")\n",
    "            print(self.root.right_data[:,-1])\n",
    "            print(\"\\n\")\"\"\"\n",
    "            \n",
    "            self.insertNode(self.root.left_data, self.root)\n",
    "            self.insertNode(self.root.right_data, self.root)\n",
    "        else:\n",
    "            self.insertNode(data, self.root)\n",
    "            \n",
    "    def insertNode(self, data, node):\n",
    "        #print(\"Inserting node\", self.count)\n",
    "        #print(self.depth())\n",
    "        self.count += 1\n",
    "        \n",
    "        #print(\"--- TESTING ---\")\n",
    "        #print(node.data[:,-1])\n",
    "        #print(node.class_predict)\n",
    "        \"\"\"print(node.left)\n",
    "        print(node.right)\n",
    "        print(\"--- ---- ---\")\"\"\"\n",
    "        \n",
    "        \"\"\"if node.class_predict:\n",
    "            print(\"BREAAAAK\")\"\"\"\n",
    "        \n",
    "        # Break condition if leaf node\n",
    "        #if not node.class_predict:\n",
    "        #if node.class_predict == -1:\n",
    "        if node.class_predict is None:\n",
    "            \n",
    "            if node.left:\n",
    "                self.insertNode(data, node.left)\n",
    "            else:\n",
    "                node.left = Node(node.left_data, self.min_sample_split, self.max_depth, node.node_depth+1)\n",
    "                try:\n",
    "                    self.insertNode(node.left.left_data, self.root) #node.left) #self.root)\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    self.insertNode(node.left.right_data, self.root) #node.right) #self.root)\n",
    "                except:\n",
    "                    pass\n",
    "                    \n",
    "            if node.right:\n",
    "                self.insertNode(data, node.right)\n",
    "            else:\n",
    "                node.right = Node(node.right_data, self.min_sample_split, self.max_depth, node.node_depth+1)\n",
    "                try:\n",
    "                    self.insertNode(node.right.left_data, self.root) #node.left) #self.root)\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    self.insertNode(node.right.right_data, self.root) #node.right) #self.root)\n",
    "                except:\n",
    "                    pass\n",
    "        else:\n",
    "            self.tree_depth.append(node.node_depth)\n",
    "            \n",
    "                \n",
    "    def fit(self, data):\n",
    "        self.insert(data)\n",
    "        \n",
    "    def traverse(self, row, node):\n",
    "        #print(row)\n",
    "        #print(node.i)\n",
    "        #if node.class_predict:\n",
    "        if node.class_predict is not None:\n",
    "            return node.class_predict\n",
    "        else:\n",
    "            if row[node.i] <= node.split_value:\n",
    "                #print(\"value\", row[node.i], \"lower or equal to\", node.split_value)\n",
    "                return self.traverse(row, node.left)\n",
    "            else:\n",
    "                return self.traverse(row, node.right)\n",
    "                #print(\"value\", row[node.i], \"higher than\", node.split_value)\n",
    "    \n",
    "    \n",
    "    def predict(self, data):\n",
    "        predictions = []\n",
    "        \n",
    "        #print(len(np.shape(data)))\n",
    "        \n",
    "        if len(np.shape(data)) > 1:\n",
    "            for row in data:\n",
    "                node = self.root\n",
    "                predictions.append(self.traverse(row, node))\n",
    "            return np.array(predictions)\n",
    "        else:\n",
    "            node = self.root\n",
    "            predictions.append(self.traverse(data, node))\n",
    "            return np.array(predictions)\n",
    "\n",
    "    def depth(self):\n",
    "        return max(self.tree_depth)\n",
    "    \n",
    "    # Old depth function\n",
    "    \"\"\"def depth(self):\n",
    "        node = self.root\n",
    "        #print(node)\n",
    "        return self.depthRecursive(node, depth=0)\n",
    "        \n",
    "    def depthRecursive(self, node, depth):\n",
    "        if node.class_predict is None:\n",
    "            depth += 1\n",
    "            if node.left:\n",
    "                return self.depthRecursive(node.left, depth)\n",
    "            if node.right:\n",
    "                return self.depthRecursive(node.right, depth)\n",
    "        else:\n",
    "            return depth \"\"\"      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metrics Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function that computes a confusion matrix which is used to compute the below functions\n",
    "def cm_maker(y, ypred, n_classes):\n",
    "    \n",
    "    low = [1, 2, 3]\n",
    "    high = [5, 6, 7]\n",
    "    \n",
    "    cm = np.zeros((n_classes, n_classes))\n",
    "    \n",
    "    for i, j in zip(ypred, y):\n",
    "        \n",
    "        if i in low:\n",
    "            i = i - 1\n",
    "        if i in high:\n",
    "            i = i - 2\n",
    "            \n",
    "        if j in low:\n",
    "            j = j - 1\n",
    "        if j in high:\n",
    "            j = j - 2\n",
    "            \n",
    "        cm[int(i), int(j)] += 1\n",
    "        \n",
    "    return cm\n",
    "\n",
    "\n",
    "# Function computes precision score\n",
    "def preci(cm, c):\n",
    "    \n",
    "    if sum(cm[c,:]) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return cm[c,c]/sum(cm[c,:])\n",
    "\n",
    "\n",
    "# Function computes recall score\n",
    "def recall(cm, c):\n",
    "    \n",
    "    return cm[c,c]/sum(cm[:,c])\n",
    "\n",
    "\n",
    "# Function computes f1-score\n",
    "def f1(cm, c):\n",
    "    if (preci(cm,c) + recall(cm,c)) == 0:\n",
    "        return 0\n",
    "    else: \n",
    "        return 2 * (preci(cm,c) * recall(cm,c)) / (preci(cm,c) + recall(cm,c))\n",
    "    \n",
    "\n",
    "# Function computes weighted f1-score\n",
    "def weighted_f1(cm, n_classes):\n",
    "    co_su=cm.sum(axis=0)\n",
    "    n=cm.sum()\n",
    "    \n",
    "    weighted_f1_sum = 0\n",
    "    \n",
    "    for c in range(n_classes):\n",
    "        if co_su[c] != 0:\n",
    "            weighted_f1_sum += f1(cm, c) * co_su[c] / n\n",
    "\n",
    "    return round(weighted_f1_sum, 3)\n",
    "        \n",
    "\n",
    "# Function computes macro f1-score\n",
    "def macro_f1(cm, n_classes):\n",
    "    \n",
    "    f1_sum = 0\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        f1_sum += f1(cm, i)\n",
    "    \n",
    "    return round(f1_sum / n_classes, 3)\n",
    "\n",
    "\n",
    "# Function to get accuracy\n",
    "def accuracy(test_y, ypred):\n",
    "    \n",
    "    # Count of times where true labels equal predictions\n",
    "    true_positives = 0\n",
    "    for i in range(len(test_y)):\n",
    "        if test_y[i] == ypred[i]:\n",
    "            true_positives += 1\n",
    "    \n",
    "    return true_positives / len(test_y)\n",
    "\n",
    "\n",
    "def accuracy_(y, ypred):\n",
    "    y, ypred = np.array(y), np.array(ypred)\n",
    "    accuracy = np.sum(y == ypred) / len(y)\n",
    "    return accuracy\n",
    "\n",
    "# Combines functions above for a coherent performance report\n",
    "def performance_report(test_y, ypred, n_classes):\n",
    "    \n",
    "    class_labels = [1, 2, 3, 5, 6, 7]\n",
    "    cm = cm_maker(test_y, ypred, n_classes)\n",
    "    \n",
    "    print('\\nConfusion matrix for prediction:\\n', cm)\n",
    "    print('\\n\\nAccuracy for prediction:\\n', accuracy(test_y, ypred))\n",
    "    \n",
    "    print('\\n\\nMetrics for classes')\n",
    "    print('_______________________________________________________________________________')\n",
    "    print('Class\\t|\\tPrecision\\t|\\tRecall\\t\\t|\\tF1 Score')\n",
    "    print('_______________________________________________________________________________')\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        \n",
    "        print('\\nClass', class_labels[i],'|\\t',round(preci(cm, i), 3),'\\t\\t|\\t',round(recall(cm, i), 3),'\\t\\t|\\t',round(f1(cm, i), 3))\n",
    "    \n",
    "    print('\\n\\nWeighted F1 score:\\n', weighted_f1(cm, n_classes))\n",
    "    print('\\nMacro F1 score:\\n', macro_f1(cm, n_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warm-up DT algorithm training (without cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the model\n",
    "# The input variable (min_sample_leaf) decides the minimum size of leaf nodes\n",
    "DT = DecisionTree(8, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fitting the model to train data\n",
    "DT.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT.depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting test data & outputs array of predictions\n",
    "y_predicted = DT.predict(test[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array of actual values\n",
    "y_actual = test[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17.,  2.,  2.,  0.,  0.,  0.],\n",
       "       [ 5., 15.,  1.,  1.,  1.,  0.],\n",
       "       [ 1.,  2.,  2.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  4.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  2.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  8.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_maker(y_actual, y_predicted,len(np.unique(train[:,-1]))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7384615384615385"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_(y_actual, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing SKLearn DT - just for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7076923076923077"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TESTING SKLEARN ####\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Hyperparamters: min_sample_split=8, max_depth=10\n",
    "clf = DecisionTreeClassifier(max_depth=10, min_samples_split=8)#, random_state=0)\n",
    "clf.fit(train[:,:-1], train[:,-1])\n",
    "sk_y_predicted = clf.predict(test[:,:-1])\n",
    "accuracy_(y_actual, sk_y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation - Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools.utils as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = sp.n_folder(5,train,shuffle_before_split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.         0.46896552]\n",
      " [4.         1.         0.46896552]\n",
      " [6.         1.         0.46896552]\n",
      " [7.         1.         0.46896552]\n",
      " [3.         1.         0.46896552]\n",
      " [8.         1.         0.46896552]\n",
      " [2.         1.         0.46896552]\n",
      " [9.         1.         0.46896552]\n",
      " [5.         1.         0.46896552]\n",
      " [2.         2.         0.57241379]\n",
      " [4.         2.         0.57241379]\n",
      " [8.         2.         0.57241379]\n",
      " [1.         2.         0.57241379]\n",
      " [5.         2.         0.57241379]\n",
      " [3.         2.         0.57241379]\n",
      " [7.         2.         0.57241379]\n",
      " [9.         2.         0.57241379]\n",
      " [6.         2.         0.57241379]\n",
      " [9.         4.         0.59310345]\n",
      " [9.         6.         0.59310345]\n",
      " [9.         5.         0.6       ]\n",
      " [5.         4.         0.60689655]\n",
      " [4.         4.         0.60689655]\n",
      " [6.         4.         0.60689655]\n",
      " [3.         4.         0.60689655]\n",
      " [1.         4.         0.60689655]\n",
      " [2.         4.         0.60689655]\n",
      " [7.         4.         0.60689655]\n",
      " [7.         6.         0.60689655]\n",
      " [5.         6.         0.60689655]\n",
      " [6.         6.         0.60689655]\n",
      " [9.         7.         0.6137931 ]\n",
      " [8.         4.         0.6137931 ]\n",
      " [9.         8.         0.6137931 ]\n",
      " [8.         6.         0.6137931 ]\n",
      " [9.         9.         0.6137931 ]\n",
      " [1.         6.         0.6137931 ]\n",
      " [7.         5.         0.6137931 ]\n",
      " [6.         5.         0.6137931 ]\n",
      " [5.         5.         0.6137931 ]\n",
      " [8.         5.         0.62068966]\n",
      " [2.         6.         0.62068966]\n",
      " [4.         6.         0.62068966]\n",
      " [3.         6.         0.62068966]\n",
      " [7.         7.         0.62758621]\n",
      " [7.         9.         0.62758621]\n",
      " [7.         8.         0.62758621]\n",
      " [1.         5.         0.62758621]\n",
      " [2.         5.         0.62758621]\n",
      " [3.         5.         0.62758621]\n",
      " [4.         5.         0.62758621]\n",
      " [8.         9.         0.63448276]\n",
      " [8.         3.         0.63448276]\n",
      " [1.         3.         0.63448276]\n",
      " [4.         3.         0.63448276]\n",
      " [9.         3.         0.63448276]\n",
      " [3.         3.         0.63448276]\n",
      " [7.         3.         0.63448276]\n",
      " [6.         3.         0.63448276]\n",
      " [8.         8.         0.63448276]\n",
      " [8.         7.         0.63448276]\n",
      " [2.         3.         0.63448276]\n",
      " [5.         3.         0.63448276]\n",
      " [1.         8.         0.64137931]\n",
      " [1.         9.         0.64137931]\n",
      " [5.         7.         0.64137931]\n",
      " [6.         7.         0.64137931]\n",
      " [5.         9.         0.64137931]\n",
      " [6.         9.         0.64137931]\n",
      " [6.         8.         0.64137931]\n",
      " [5.         8.         0.64137931]\n",
      " [2.         8.         0.64827586]\n",
      " [2.         9.         0.64827586]\n",
      " [3.         9.         0.65517241]\n",
      " [4.         9.         0.65517241]\n",
      " [3.         8.         0.65517241]\n",
      " [3.         7.         0.65517241]\n",
      " [1.         7.         0.65517241]\n",
      " [4.         7.         0.65517241]\n",
      " [4.         8.         0.65517241]\n",
      " [2.         7.         0.66206897]]\n"
     ]
    }
   ],
   "source": [
    "cross_accuracies = []\n",
    "\n",
    "for i in range(1,10):\n",
    "    for j in range(1,10):\n",
    "        \n",
    "        cv_acc = []\n",
    "        for idx, item in enumerate(sets):\n",
    "\n",
    "            cross_test, cross_train = item  \n",
    "            cross_DT = DecisionTree(i, j) \n",
    "            cross_DT.fit(cross_train)\n",
    "            cross_y_predicted = cross_DT.predict(cross_test[:,:-1])\n",
    "            cross_y_actual = cross_test[:,-1]\n",
    "            \n",
    "            cross_accuracy = accuracy_(cross_y_actual, cross_y_predicted)\n",
    "            cv_acc.append(cross_accuracy)\n",
    "            \n",
    "        cross_accuracies.append([i, j, np.mean(cv_acc)])\n",
    "\n",
    "    \n",
    "a = np.array(cross_accuracies)\n",
    "sorted_a = a[np.argsort(a[:, -1])]\n",
    "\n",
    "print(sorted_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the cross validation test we can see that <b>min_sample_split=4</b> and <b>max_depth=5</b> yielded the best results for multiclass with an <b>accuracy of ~0.62</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final evaluation - Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix for prediction:\n",
      " [[18.  1.  1.  0.  1.  0.]\n",
      " [ 1. 18.  2.  0.  0.  0.]\n",
      " [ 2.  1.  2.  0.  0.  1.]\n",
      " [ 0.  2.  0.  4.  0.  0.]\n",
      " [ 0.  1.  0.  0.  2.  0.]\n",
      " [ 0.  0.  0.  0.  0.  8.]]\n",
      "\n",
      "\n",
      "Accuracy for prediction:\n",
      " 0.8\n",
      "\n",
      "\n",
      "Metrics for classes\n",
      "_______________________________________________________________________________\n",
      "Class\t|\tPrecision\t|\tRecall\t\t|\tF1 Score\n",
      "_______________________________________________________________________________\n",
      "\n",
      "Class 1 |\t 0.857 \t\t|\t 0.857 \t\t|\t 0.857\n",
      "\n",
      "Class 2 |\t 0.857 \t\t|\t 0.783 \t\t|\t 0.818\n",
      "\n",
      "Class 3 |\t 0.333 \t\t|\t 0.4 \t\t|\t 0.364\n",
      "\n",
      "Class 5 |\t 0.667 \t\t|\t 1.0 \t\t|\t 0.8\n",
      "\n",
      "Class 6 |\t 0.667 \t\t|\t 0.667 \t\t|\t 0.667\n",
      "\n",
      "Class 7 |\t 1.0 \t\t|\t 0.889 \t\t|\t 0.941\n",
      "\n",
      "\n",
      "Weighted F1 score:\n",
      " 0.805\n",
      "\n",
      "Macro F1 score:\n",
      " 0.741\n"
     ]
    }
   ],
   "source": [
    "DT = DecisionTree(4, 5)\n",
    "DT.fit(train)\n",
    "y_predicted = DT.predict(test[:,:-1])\n",
    "y_actual = test[:,-1]\n",
    "        \n",
    "performance_report(y_actual, y_predicted, n_classes=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation - Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data to Window (1) and non-Window (0):\n",
    "\n",
    "# Loading data\n",
    "train2, test2 = \"data/df_train.csv\", \"data/df_test.csv\"\n",
    "train2 = np.loadtxt(train2, skiprows=1, delimiter=\",\")\n",
    "test2 = np.loadtxt(test2, skiprows=1, delimiter=\",\")\n",
    "\n",
    "for idx,i in enumerate(train2):\n",
    "    if i[-1] == 1 or i[-1] == 2 or i[-1] == 3:\n",
    "        train2[idx,-1] = 1\n",
    "    else:\n",
    "        train2[idx,-1] = 2\n",
    "        \n",
    "for idx,i in enumerate(test2):\n",
    "    if i[-1] == 1 or i[-1] == 2 or i[-1] == 3:\n",
    "        test2[idx,-1] = 1\n",
    "    else:\n",
    "        test2[idx,-1] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = sp.n_folder(5,train2,shuffle_before_split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.         0.46896552]\n",
      " [4.         1.         0.46896552]\n",
      " [6.         1.         0.46896552]\n",
      " [7.         1.         0.46896552]\n",
      " [3.         1.         0.46896552]\n",
      " [8.         1.         0.46896552]\n",
      " [2.         1.         0.46896552]\n",
      " [9.         1.         0.46896552]\n",
      " [5.         1.         0.46896552]\n",
      " [2.         2.         0.57241379]\n",
      " [4.         2.         0.57241379]\n",
      " [8.         2.         0.57241379]\n",
      " [1.         2.         0.57241379]\n",
      " [5.         2.         0.57241379]\n",
      " [3.         2.         0.57241379]\n",
      " [7.         2.         0.57241379]\n",
      " [9.         2.         0.57241379]\n",
      " [6.         2.         0.57241379]\n",
      " [9.         4.         0.59310345]\n",
      " [9.         6.         0.59310345]\n",
      " [9.         5.         0.6       ]\n",
      " [5.         4.         0.60689655]\n",
      " [4.         4.         0.60689655]\n",
      " [6.         4.         0.60689655]\n",
      " [3.         4.         0.60689655]\n",
      " [1.         4.         0.60689655]\n",
      " [2.         4.         0.60689655]\n",
      " [7.         4.         0.60689655]\n",
      " [7.         6.         0.60689655]\n",
      " [5.         6.         0.60689655]\n",
      " [6.         6.         0.60689655]\n",
      " [9.         7.         0.6137931 ]\n",
      " [8.         4.         0.6137931 ]\n",
      " [9.         8.         0.6137931 ]\n",
      " [8.         6.         0.6137931 ]\n",
      " [9.         9.         0.6137931 ]\n",
      " [1.         6.         0.6137931 ]\n",
      " [7.         5.         0.6137931 ]\n",
      " [6.         5.         0.6137931 ]\n",
      " [5.         5.         0.6137931 ]\n",
      " [8.         5.         0.62068966]\n",
      " [2.         6.         0.62068966]\n",
      " [4.         6.         0.62068966]\n",
      " [3.         6.         0.62068966]\n",
      " [7.         7.         0.62758621]\n",
      " [7.         9.         0.62758621]\n",
      " [7.         8.         0.62758621]\n",
      " [1.         5.         0.62758621]\n",
      " [2.         5.         0.62758621]\n",
      " [3.         5.         0.62758621]\n",
      " [4.         5.         0.62758621]\n",
      " [8.         9.         0.63448276]\n",
      " [8.         3.         0.63448276]\n",
      " [1.         3.         0.63448276]\n",
      " [4.         3.         0.63448276]\n",
      " [9.         3.         0.63448276]\n",
      " [3.         3.         0.63448276]\n",
      " [7.         3.         0.63448276]\n",
      " [6.         3.         0.63448276]\n",
      " [8.         8.         0.63448276]\n",
      " [8.         7.         0.63448276]\n",
      " [2.         3.         0.63448276]\n",
      " [5.         3.         0.63448276]\n",
      " [1.         8.         0.64137931]\n",
      " [1.         9.         0.64137931]\n",
      " [5.         7.         0.64137931]\n",
      " [6.         7.         0.64137931]\n",
      " [5.         9.         0.64137931]\n",
      " [6.         9.         0.64137931]\n",
      " [6.         8.         0.64137931]\n",
      " [5.         8.         0.64137931]\n",
      " [2.         8.         0.64827586]\n",
      " [2.         9.         0.64827586]\n",
      " [3.         9.         0.65517241]\n",
      " [4.         9.         0.65517241]\n",
      " [3.         8.         0.65517241]\n",
      " [3.         7.         0.65517241]\n",
      " [1.         7.         0.65517241]\n",
      " [4.         7.         0.65517241]\n",
      " [4.         8.         0.65517241]\n",
      " [2.         7.         0.66206897]]\n"
     ]
    }
   ],
   "source": [
    "bi_cross_accuracies = []\n",
    "\n",
    "for i in range(1,10):\n",
    "    for j in range(1,10):\n",
    "        \n",
    "        cv_acc = []\n",
    "        for idx, item in enumerate(sets):\n",
    "\n",
    "            cross_test, cross_train = item  \n",
    "            cross_DT = DecisionTree(i, j) \n",
    "            cross_DT.fit(cross_train)\n",
    "            cross_y_predicted = cross_DT.predict(cross_test[:,:-1])\n",
    "            cross_y_actual = cross_test[:,-1]\n",
    "            \n",
    "            cross_accuracy = accuracy_(cross_y_actual, cross_y_predicted)\n",
    "            cv_acc.append(cross_accuracy)\n",
    "            \n",
    "        bi_cross_accuracies.append([i, j, np.mean(cv_acc)])\n",
    "\n",
    "    \n",
    "a = np.array(cross_accuracies)\n",
    "sorted_a = a[np.argsort(a[:, -1])]\n",
    "\n",
    "print(sorted_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the cross validation test we can see that <b>min_sample_split=4</b> and <b>max_depth=5</b> yielded the best results for binary classification with an <b>accuracy of ~0.62</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final evaluation - Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix for prediction:\n",
      " [[47.  1.]\n",
      " [ 2. 15.]]\n",
      "\n",
      "\n",
      "Accuracy for prediction:\n",
      " 0.9538461538461539\n",
      "\n",
      "\n",
      "Metrics for classes\n",
      "_______________________________________________________________________________\n",
      "Class\t|\tPrecision\t|\tRecall\t\t|\tF1 Score\n",
      "_______________________________________________________________________________\n",
      "\n",
      "Class 1 |\t 0.979 \t\t|\t 0.959 \t\t|\t 0.969\n",
      "\n",
      "Class 2 |\t 0.882 \t\t|\t 0.938 \t\t|\t 0.909\n",
      "\n",
      "\n",
      "Weighted F1 score:\n",
      " 0.954\n",
      "\n",
      "Macro F1 score:\n",
      " 0.939\n"
     ]
    }
   ],
   "source": [
    "bi_DT = DecisionTree(4, 5)\n",
    "bi_DT.fit(train2)\n",
    "bi_y_predicted = bi_DT.predict(test2[:,:-1])\n",
    "bi_y_actual = test2[:,-1]\n",
    "        \n",
    "performance_report(bi_y_actual.astype(int), bi_y_predicted, n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
