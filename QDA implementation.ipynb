{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA on data for feature selection / Avoid collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of PCA using numpy\n",
    "def PCA_dim_reduction(train_file, test_file, n_components):\n",
    "    \n",
    "    # Read data\n",
    "    train = np.loadtxt(train_file, skiprows=1, delimiter=\",\")\n",
    "    test = np.loadtxt(test_file, skiprows=1, delimiter=\",\")\n",
    "\n",
    "    train_x = train[:,:-1]  \n",
    "    train_y = train[:,-1]\n",
    "\n",
    "    test_x = test[:,:-1]\n",
    "    test_y = test[:,-1]\n",
    "    \n",
    "    # Standardize data\n",
    "    mean = np.mean(train_x, axis=0)\n",
    "    std = np.std(train_x, axis=0)\n",
    "    \n",
    "    train_x = (train_x - mean) / std\n",
    "    test_x = (test_x - mean) / std\n",
    "    \n",
    "    # Get covariance matrix\n",
    "    covmat = np.cov(train_x.T)\n",
    "    \n",
    "    # Get eigenvalues\n",
    "    eigval, eigvec = np.linalg.eig(covmat)\n",
    "    \n",
    "    # Get explained variance (if needed)\n",
    "    exp_var = []\n",
    "    for i in range(len(eigval)):\n",
    "        exp_var.append(eigval[i]/np.sum(eigval))\n",
    "    exp_var = sorted(exp_var, reverse=True)\n",
    "\n",
    "    # Pair up eigenvalues and vectors, so the vectors can be ranked by values\n",
    "    eigenpairs = []\n",
    "    for i in range(len(eigval)):\n",
    "        eigenpairs.append((eigval[i]/np.sum(eigval), eigvec[:, i].T))\n",
    "    eigenpairs = sorted(eigenpairs, reverse=True)\n",
    "    \n",
    "    # Put in the vectors from most to least important in a list\n",
    "    sorted_vectors = []\n",
    "    for i in range(len(eigenpairs)):\n",
    "        sorted_vectors.append(eigenpairs[i][1])\n",
    "    \n",
    "    # Make new variables to store the transformed data (the n principle coponents)\n",
    "    new_train_x = np.zeros((len(train_x), n_components))\n",
    "    new_test_x = np.zeros((len(test_x), n_components))\n",
    "    \n",
    "    # Transform the data into n principle components on the new subspace\n",
    "    for i in range(n_components):\n",
    "        new_train_x[:,i] = train_x @ sorted_vectors[i]\n",
    "        new_test_x[:,i] = test_x @ sorted_vectors[i]\n",
    "    \n",
    "    # Store transformed data (pc's) in old variables\n",
    "    train_x = new_train_x\n",
    "    test_x = new_test_x\n",
    "    \n",
    "    # Return the transformed train and test data + class labels\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QDA Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to put the class specific data into designated arrays\n",
    "def preprocess_QDA(train_x, train_y):\n",
    "    # Collecting all class labels\n",
    "    classes = np.unique(train_y)\n",
    "\n",
    "    # Seperating all class-specific observations onto designated variables and finally collecting them into an array.\n",
    "    mask = train_y == 1\n",
    "    class1 = train_x[mask, :]\n",
    "\n",
    "    mask = train_y == 2\n",
    "    class2 = train_x[mask, :]\n",
    "\n",
    "    mask = train_y  == 3\n",
    "    class3 = train_x[mask, :]\n",
    "\n",
    "    mask = train_y == 5\n",
    "    class5 = train_x[mask, :]\n",
    "\n",
    "    mask = train_y == 6\n",
    "    class6 = train_x[mask, :]\n",
    "\n",
    "    mask = train_y == 7\n",
    "    class7 = train_x[mask, :]\n",
    "    \n",
    "    # list of arrays with observations from specific classes\n",
    "    class_list = [class1, class2, class3, class5, class6, class7]\n",
    "    \n",
    "    # Return list with arrays of observations in classes\n",
    "    return class_list\n",
    "\n",
    "\n",
    "# Function to get the class parameters: mean, covariance matrix and probability of class\n",
    "def get_parameters_QDA(class_list, train_x):\n",
    "    \n",
    "    # Estimate a mean vector per class\n",
    "    class_means = np.zeros((len(class_list), train_x.shape[1]))\n",
    "    for i in range(len(class_list)):\n",
    "        class_means[i] = class_list[i].mean(axis=0)\n",
    "\n",
    "    # Estimate a covariance matrix per class\n",
    "    class_covmats = []\n",
    "    for i in range(len(class_list)):\n",
    "        class_covmats.append(np.cov(class_list[i].T))\n",
    "\n",
    "\n",
    "    # Estimate class probabilities\n",
    "    class_probs = []\n",
    "    for i in range(len(class_list)):\n",
    "        class_probs.append(len(class_list[i]) / len(train_x))\n",
    "    \n",
    "    # Return the parameters for each class in designated lists\n",
    "    return class_means, class_covmats, class_probs\n",
    "\n",
    "\n",
    "# Discriminant function from slides\n",
    "# It takes in a specific observation and the parameters of a specific class\n",
    "def QDA_discriminant_function(x, class_mean, class_covmat, class_prob):\n",
    "    \n",
    "    a_k = 2 * np.log(class_prob) - np.log(np.linalg.det(class_covmat)) - class_mean.T @ np.linalg.inv(class_covmat) @ class_mean\n",
    "    b_k = 2 * class_mean.T @ np.linalg.inv(class_covmat)\n",
    "    c_k = -np.linalg.inv(class_covmat)\n",
    "    \n",
    "    # Returns discriminant function for a specific class on a specific observation\n",
    "    return a_k + b_k.T @ x + x.T @ c_k @ x\n",
    "\n",
    "\n",
    "# QDA scoring by finding the class that maximises the dicriminant function for each observation\n",
    "def QDA_class_scoring(test_x, test_y, class_list, covmat_list, mean_list, prob_list):\n",
    "    \n",
    "    classes = np.unique(test_y)\n",
    "    class_scores = np.zeros((len(test_x), len(class_list)))\n",
    "    \n",
    "    for x in range(len(test_x)):\n",
    "        for k in range(len(class_list)):\n",
    "            # formula from lectures\n",
    "            class_scores[x, k] = QDA_discriminant_function(test_x[x,:], mean_list[k], covmat_list[k], prob_list[k])\n",
    "            \n",
    "            # formula from sklearn library\n",
    "            #class_scores[x, k] = log_posterior_sklearn(test_x[x,:], mean_list[k], covmat_list[k], prob_list[k])\n",
    "    \n",
    "    # List of classes that maximises the dicsriminant function for each observation\n",
    "    class_max = []\n",
    "    for row in class_scores:\n",
    "        class_max.append(int(classes[np.argmax(row)]))\n",
    "    \n",
    "    # returns list with the class that maximised the discriminant function for each observation\n",
    "    return class_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to get metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that computes a confusion matrix which is used to compute the below functions\n",
    "def cm_maker(y, ypred, n_classes):\n",
    "    \n",
    "    low = [1, 2, 3]\n",
    "    high = [5, 6, 7]\n",
    "    \n",
    "    cm = np.zeros((n_classes, n_classes))\n",
    "    \n",
    "    for i, j in zip(ypred, y):\n",
    "        \n",
    "        if i in low:\n",
    "            i = i - 1\n",
    "        if i in high:\n",
    "            i = i - 2\n",
    "            \n",
    "        if j in low:\n",
    "            j = j - 1\n",
    "        if j in high:\n",
    "            j = j - 2\n",
    "            \n",
    "        cm[int(i), int(j)] += 1\n",
    "        \n",
    "    return cm\n",
    "\n",
    "\n",
    "# Function computes precision score\n",
    "def preci(cm, c):\n",
    "    \n",
    "    if sum(cm[c,:]) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return cm[c,c]/sum(cm[c,:])\n",
    "\n",
    "\n",
    "# Function computes recall score\n",
    "def recall(cm, c):\n",
    "    \n",
    "    return cm[c,c]/sum(cm[:,c])\n",
    "\n",
    "\n",
    "# Function computes f1-score\n",
    "def f1(cm, c):\n",
    "    if (preci(cm,c) + recall(cm,c)) == 0:\n",
    "        return 0\n",
    "    else: \n",
    "        return 2 * (preci(cm,c) * recall(cm,c)) / (preci(cm,c) + recall(cm,c))\n",
    "    \n",
    "\n",
    "# Function computes weighted f1-score\n",
    "def weighted_f1(cm, n_classes):\n",
    "    co_su=cm.sum(axis=0)\n",
    "    n=cm.sum()\n",
    "    \n",
    "    weighted_f1_sum = 0\n",
    "    \n",
    "    for c in range(n_classes):\n",
    "        if co_su[c] != 0:\n",
    "            weighted_f1_sum += f1(cm, c) * co_su[c] / n\n",
    "\n",
    "    return round(weighted_f1_sum, 3)\n",
    "        \n",
    "\n",
    "# Function computes macro f1-score\n",
    "def macro_f1(cm, n_classes):\n",
    "    \n",
    "    f1_sum = 0\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        f1_sum += f1(cm, i)\n",
    "    \n",
    "    return round(f1_sum / n_classes, 3)\n",
    "\n",
    "\n",
    "# Function to get accuracy\n",
    "def accuracy(test_y, ypred):\n",
    "    \n",
    "    # Count of times where true labels equal predictions\n",
    "    true_positives = 0\n",
    "    for i in range(len(test_y)):\n",
    "        if test_y[i] == ypred[i]:\n",
    "            true_positives += 1\n",
    "    \n",
    "    return true_positives / len(test_y)\n",
    "\n",
    "\n",
    "# Combines functions above for a coherent performance report\n",
    "def performance_report(test_y, ypred, n_classes):\n",
    "    \n",
    "    class_labels = [1, 2, 3, 5, 6, 7]\n",
    "    cm = cm_maker(test_y, ypred, n_classes)\n",
    "    \n",
    "    print('\\nConfusion matrix for prediction:\\n', cm)\n",
    "    print('\\n\\nAccuracy for prediction:\\n', accuracy(test_y, ypred))\n",
    "    \n",
    "    print('\\n\\nMetrics for classes')\n",
    "    print('_______________________________________________________________________________')\n",
    "    print('Class\\t|\\tPrecision\\t|\\tRecall\\t\\t|\\tF1 Score')\n",
    "    print('_______________________________________________________________________________')\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        \n",
    "        print('\\nClass', class_labels[i],'|\\t',round(preci(cm, i), 3),'\\t\\t|\\t',round(recall(cm, i), 3),'\\t\\t|\\t',round(f1(cm, i), 3))\n",
    "    \n",
    "    print('\\n\\nWeighted F1 score:\\n', weighted_f1(cm, n_classes))\n",
    "    print('\\nMacro F1 score:\\n', macro_f1(cm, n_classes))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QDA with PCA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix for prediction:\n",
      " [[20. 14.  4.  0.  0.  0.]\n",
      " [ 0.  7.  0.  1.  1.  0.]\n",
      " [ 1.  1.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  3.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  2.  8.]]\n",
      "\n",
      "\n",
      "Accuracy for prediction:\n",
      " 0.6\n",
      "\n",
      "\n",
      "Metrics for classes\n",
      "_______________________________________________________________________________\n",
      "Class\t|\tPrecision\t|\tRecall\t\t|\tF1 Score\n",
      "_______________________________________________________________________________\n",
      "\n",
      "Class 1 |\t 0.526 \t\t|\t 0.952 \t\t|\t 0.678\n",
      "\n",
      "Class 2 |\t 0.778 \t\t|\t 0.304 \t\t|\t 0.438\n",
      "\n",
      "Class 3 |\t 0.333 \t\t|\t 0.2 \t\t|\t 0.25\n",
      "\n",
      "Class 5 |\t 0.6 \t\t|\t 0.75 \t\t|\t 0.667\n",
      "\n",
      "Class 6 |\t 0 \t\t|\t 0.0 \t\t|\t 0\n",
      "\n",
      "Class 7 |\t 0.8 \t\t|\t 0.889 \t\t|\t 0.842\n",
      "\n",
      "\n",
      "Weighted F1 score:\n",
      " 0.551\n",
      "\n",
      "Macro F1 score:\n",
      " 0.479\n"
     ]
    }
   ],
   "source": [
    "# Get PC's from train/test data\n",
    "train_x, train_y, test_x, test_y = PCA_dim_reduction('df_train.csv', 'df_test.csv', 5)\n",
    "\n",
    "# Get class observations in arrays in a list\n",
    "class_list = preprocess_QDA(train_x, train_y)\n",
    "\n",
    "# Get class means, covariance matrices and probabilities\n",
    "mean_list, covmat_list, prob_list = get_parameters_QDA(class_list, train_x)\n",
    "\n",
    "# Get y predictions (class that maximises the discriminant function for each observation)\n",
    "ypred = QDA_class_scoring(test_x, test_y, class_list, covmat_list, mean_list, prob_list)\n",
    "\n",
    "# Get performance report on the classification metrics\n",
    "performance_report(test_y, ypred, len(class_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QDA with sklearn on PCA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix for prediction:\n",
      " [[20. 14.  4.  0.  0.  0.]\n",
      " [ 0.  7.  0.  1.  1.  0.]\n",
      " [ 1.  1.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  3.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  2.  8.]]\n",
      "\n",
      "\n",
      "Accuracy for prediction:\n",
      " 0.6\n",
      "\n",
      "\n",
      "Metrics for classes\n",
      "_______________________________________________________________________________\n",
      "Class\t|\tPrecision\t|\tRecall\t\t|\tF1 Score\n",
      "_______________________________________________________________________________\n",
      "\n",
      "Class 1 |\t 0.526 \t\t|\t 0.952 \t\t|\t 0.678\n",
      "\n",
      "Class 2 |\t 0.778 \t\t|\t 0.304 \t\t|\t 0.438\n",
      "\n",
      "Class 3 |\t 0.333 \t\t|\t 0.2 \t\t|\t 0.25\n",
      "\n",
      "Class 5 |\t 0.6 \t\t|\t 0.75 \t\t|\t 0.667\n",
      "\n",
      "Class 6 |\t 0 \t\t|\t 0.0 \t\t|\t 0\n",
      "\n",
      "Class 7 |\t 0.8 \t\t|\t 0.889 \t\t|\t 0.842\n",
      "\n",
      "\n",
      "Weighted F1 score:\n",
      " 0.551\n",
      "\n",
      "Macro F1 score:\n",
      " 0.479\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "qda = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "\n",
    "train_x, train_y, test_x, test_y = PCA_dim_reduction('df_train.csv', 'df_test.csv', 5)\n",
    "\n",
    "qda.fit(train_x, train_y)\n",
    "\n",
    "ypred = qda.predict(test_x)\n",
    "\n",
    "performance_report(test_y, ypred, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QDA when combining data into window/non-window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix for prediction:\n",
      " [[47.  1.]\n",
      " [ 2. 15.]]\n",
      "\n",
      "\n",
      "Accuracy for prediction:\n",
      " 0.9538461538461539\n",
      "\n",
      "\n",
      "Metrics for classes\n",
      "_______________________________________________________________________________\n",
      "Class\t|\tPrecision\t|\tRecall\t\t|\tF1 Score\n",
      "_______________________________________________________________________________\n",
      "\n",
      "Class 1 |\t 0.979 \t\t|\t 0.959 \t\t|\t 0.969\n",
      "\n",
      "Class 2 |\t 0.882 \t\t|\t 0.938 \t\t|\t 0.909\n",
      "\n",
      "\n",
      "Weighted F1 score:\n",
      " 0.954\n",
      "\n",
      "Macro F1 score:\n",
      " 0.939\n"
     ]
    }
   ],
   "source": [
    "# Read in the top 5 Principal Components\n",
    "train_x, train_y, test_x, test_y = PCA_dim_reduction('df_train.csv', 'df_test.csv', 5)\n",
    "    \n",
    "# Divide test and train data into features and class labels\n",
    "window = [1,2,3]\n",
    "\n",
    "for i in range(len(train_y)):\n",
    "    if train_y[i] in window:\n",
    "        train_y[i] = 1\n",
    "    else:\n",
    "        train_y[i] = 2\n",
    "\n",
    "for i in range(len(test_y)):\n",
    "    if test_y[i] in window:\n",
    "        test_y[i] = 1\n",
    "    else:\n",
    "        test_y[i] = 2\n",
    "        \n",
    "mask = train_y == 1\n",
    "class1 = train_x[mask, :]\n",
    "\n",
    "mask = train_y == 2\n",
    "class2 = train_x[mask, :]\n",
    "\n",
    "# Class list for combined classes\n",
    "class_list = [class1, class2]\n",
    "\n",
    "# Get class means, covariance matrices and probabilities\n",
    "mean_list, covmat_list, prob_list = get_parameters_QDA(class_list, train_x)\n",
    "\n",
    "# Get y predictions (class that maximises the discriminant function for each observation)\n",
    "ypred = QDA_class_scoring(test_x, test_y, class_list, covmat_list, mean_list, prob_list)\n",
    "\n",
    "# Get performance report on the classification metrics\n",
    "performance_report(test_y, ypred, len(class_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
