{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "train, test = \"data/df_train.csv\", \"data/df_test.csv\"\n",
    "train = np.loadtxt(train, skiprows=1, delimiter=\",\")\n",
    "test = np.loadtxt(test, skiprows=1, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metrics Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that computes a confusion matrix which is used to compute the below functions\n",
    "def cm_maker(y, ypred, n_classes):\n",
    "    \n",
    "    low = [1, 2, 3]\n",
    "    high = [5, 6, 7]\n",
    "    \n",
    "    cm = np.zeros((n_classes, n_classes))\n",
    "    \n",
    "    for i, j in zip(ypred, y):\n",
    "        \n",
    "        if i in low:\n",
    "            i = i - 1\n",
    "        if i in high:\n",
    "            i = i - 2\n",
    "            \n",
    "        if j in low:\n",
    "            j = j - 1\n",
    "        if j in high:\n",
    "            j = j - 2\n",
    "            \n",
    "        cm[int(i), int(j)] += 1\n",
    "        \n",
    "    return cm\n",
    "\n",
    "\n",
    "# Function computes precision score\n",
    "def preci(cm, c):\n",
    "    \n",
    "    if sum(cm[c,:]) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return cm[c,c]/sum(cm[c,:])\n",
    "\n",
    "\n",
    "# Function computes recall score\n",
    "def recall(cm, c):\n",
    "    \n",
    "    return cm[c,c]/sum(cm[:,c])\n",
    "\n",
    "\n",
    "# Function computes f1-score\n",
    "def f1(cm, c):\n",
    "    if (preci(cm,c) + recall(cm,c)) == 0:\n",
    "        return 0\n",
    "    else: \n",
    "        return 2 * (preci(cm,c) * recall(cm,c)) / (preci(cm,c) + recall(cm,c))\n",
    "    \n",
    "\n",
    "# Function computes weighted f1-score\n",
    "def weighted_f1(cm, n_classes):\n",
    "    co_su=cm.sum(axis=0)\n",
    "    n=cm.sum()\n",
    "    \n",
    "    weighted_f1_sum = 0\n",
    "    \n",
    "    for c in range(n_classes):\n",
    "        if co_su[c] != 0:\n",
    "            weighted_f1_sum += f1(cm, c) * co_su[c] / n\n",
    "\n",
    "    return round(weighted_f1_sum, 3)\n",
    "        \n",
    "\n",
    "# Function computes macro f1-score\n",
    "def macro_f1(cm, n_classes):\n",
    "    \n",
    "    f1_sum = 0\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        f1_sum += f1(cm, i)\n",
    "    \n",
    "    return round(f1_sum / n_classes, 3)\n",
    "\n",
    "\n",
    "# Function to get accuracy\n",
    "def accuracy(test_y, ypred):\n",
    "    \n",
    "    # Count of times where true labels equal predictions\n",
    "    true_positives = 0\n",
    "    for i in range(len(test_y)):\n",
    "        if test_y[i] == ypred[i]:\n",
    "            true_positives += 1\n",
    "    \n",
    "    return true_positives / len(test_y)\n",
    "\n",
    "\n",
    "# Combines functions above for a coherent performance report\n",
    "def performance_report(test_y, ypred, n_classes):\n",
    "    \n",
    "    class_labels = [1, 2, 3, 5, 6, 7]\n",
    "    cm = cm_maker(test_y, ypred, n_classes)\n",
    "    \n",
    "    print('\\nConfusion matrix for prediction:\\n', cm)\n",
    "    print('\\n\\nAccuracy for prediction:\\n', accuracy(test_y, ypred))\n",
    "    \n",
    "    print('\\n\\nMetrics for classes')\n",
    "    print('_______________________________________________________________________________')\n",
    "    print('Class\\t|\\tPrecision\\t|\\tRecall\\t\\t|\\tF1 Score')\n",
    "    print('_______________________________________________________________________________')\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        \n",
    "        print('\\nClass', class_labels[i],'|\\t',round(preci(cm, i), 3),'\\t\\t|\\t',round(recall(cm, i), 3),'\\t\\t|\\t',round(f1(cm, i), 3))\n",
    "    \n",
    "    print('\\n\\nWeighted F1 score:\\n', weighted_f1(cm, n_classes))\n",
    "    print('\\nMacro F1 score:\\n', macro_f1(cm, n_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation - Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitter as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = sp.n_folder(5,train,shuffle_before_split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         2.         3.33333333 0.01       0.26896552]\n",
      " [1.         2.         2.66666667 0.01       0.27586207]\n",
      " [1.         2.         3.66666667 0.01       0.27586207]\n",
      " ...\n",
      " [3.         5.         1.66666667 0.1        0.64137931]\n",
      " [3.         3.         1.66666667 0.1        0.64137931]\n",
      " [3.         4.         1.66666667 0.1        0.64137931]]\n"
     ]
    }
   ],
   "source": [
    "cross_accuracies = []\n",
    "\n",
    "for i in range(1,6):\n",
    "    #print(\"i:\",i)\n",
    "    for j in range(1,10):\n",
    "        #print(\"j:\",j)\n",
    "        for k in range(1,12):\n",
    "            #print(\"k:\",k)\n",
    "            for l in range(1,4):\n",
    "                if l == 1:\n",
    "                    kernel_ = \"poly\"\n",
    "                if l == 2:\n",
    "                    kernel_ = \"linear\"\n",
    "                if l == 3:\n",
    "                    kernel_ = \"rbf\"\n",
    "\n",
    "                k_ = k/3\n",
    "\n",
    "                cv_acc = []\n",
    "                for idx, item in enumerate(sets):\n",
    "                    cross_test, cross_train = item  \n",
    "\n",
    "                    cross_svm = Pipeline(((\"scaler\", StandardScaler()),\n",
    "                                         (\"svm_clf\", SVC(kernel=kernel_,\n",
    "                                                        degree=i, C=k_, gamma=100/(10**j)))))   # coef0=j\n",
    "\n",
    "                    cross_svm.fit(cross_train[:,:-1], cross_train[:,-1])\n",
    "                    cross_y_predicted = cross_svm.predict(cross_test[:,:-1])\n",
    "                    cross_y_actual = cross_test[:,-1]\n",
    "\n",
    "                    cross_accuracy = accuracy_(cross_y_actual, cross_y_predicted)\n",
    "                    cv_acc.append(cross_accuracy)\n",
    "\n",
    "\n",
    "                cross_accuracies.append([l, i, k_, 100/(10**j), np.mean(cv_acc)])\n",
    "\n",
    "    \n",
    "a = np.array(cross_accuracies)\n",
    "sorted_a = a[np.argsort(a[:, -1])]\n",
    "\n",
    "print(sorted_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the cross validation test we can see that <b>kernel=rbf</b>, <b>degree=n/a</b>, <b>C=4/3</b> and <b>gamma=0.1</b> yielded the best results for multiclass with an <b>accuracy of ~0.66</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final evaluation - Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix for prediction:\n",
      " [[18.  1.  2.  0.  1.  0.]\n",
      " [ 3. 19.  3.  1.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  2.  0.  3.  0.  0.]\n",
      " [ 0.  1.  0.  0.  2.  0.]\n",
      " [ 0.  0.  0.  0.  0.  8.]]\n",
      "\n",
      "\n",
      "Accuracy for prediction:\n",
      " 0.7692307692307693\n",
      "\n",
      "\n",
      "Metrics for classes\n",
      "_______________________________________________________________________________\n",
      "Class\t|\tPrecision\t|\tRecall\t\t|\tF1 Score\n",
      "_______________________________________________________________________________\n",
      "\n",
      "Class 1 |\t 0.818 \t\t|\t 0.857 \t\t|\t 0.837\n",
      "\n",
      "Class 2 |\t 0.704 \t\t|\t 0.826 \t\t|\t 0.76\n",
      "\n",
      "Class 3 |\t 0 \t\t|\t 0.0 \t\t|\t 0\n",
      "\n",
      "Class 5 |\t 0.6 \t\t|\t 0.75 \t\t|\t 0.667\n",
      "\n",
      "Class 6 |\t 0.667 \t\t|\t 0.667 \t\t|\t 0.667\n",
      "\n",
      "Class 7 |\t 1.0 \t\t|\t 0.889 \t\t|\t 0.941\n",
      "\n",
      "\n",
      "Weighted F1 score:\n",
      " 0.742\n",
      "\n",
      "Macro F1 score:\n",
      " 0.645\n"
     ]
    }
   ],
   "source": [
    "svm = Pipeline(((\"scaler\", StandardScaler()),\n",
    "                        (\"svm_clf\", SVC(kernel=\"rbf\",\n",
    "                        degree=5, C=4/3, gamma=0.1))))\n",
    "                \n",
    "svm.fit(train[:,:-1], train[:,-1])\n",
    "y_predicted = svm.predict(test[:,:-1])\n",
    "y_actual = test[:,-1]\n",
    "        \n",
    "performance_report(y_actual, y_predicted, n_classes=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation - Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data to Window (1) and non-Window (0):\n",
    "\n",
    "# Loading data\n",
    "train2, test2 = \"data/df_train.csv\", \"data/df_test.csv\"\n",
    "train2 = np.loadtxt(train2, skiprows=1, delimiter=\",\")\n",
    "test2 = np.loadtxt(test2, skiprows=1, delimiter=\",\")\n",
    "\n",
    "for idx,i in enumerate(train2):\n",
    "    if i[-1] == 1 or i[-1] == 2 or i[-1] == 3:\n",
    "        train2[idx,-1] = 1\n",
    "    else:\n",
    "        train2[idx,-1] = 2\n",
    "        \n",
    "for idx,i in enumerate(test2):\n",
    "    if i[-1] == 1 or i[-1] == 2 or i[-1] == 3:\n",
    "        test2[idx,-1] = 1\n",
    "    else:\n",
    "        test2[idx,-1] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = sp.n_folder(5,train2,shuffle_before_split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-38bbfaea2ef3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m                                                         degree=i, C=k_, gamma=100/(10**j)))))   # coef0=j\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                     \u001b[0mcross_svm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                     \u001b[0mcross_y_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_svm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mcross_y_actual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kaspergroenbek98/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \"\"\"\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         with _print_elapsed_time('Pipeline',\n",
      "\u001b[0;32m/home/kaspergroenbek98/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_check_fit_params\u001b[0;34m(self, **fit_params)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         fit_params_steps = {name: {} for name, step in self.steps\n\u001b[0m\u001b[1;32m    240\u001b[0m                             if step is not None}\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kaspergroenbek98/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         fit_params_steps = {name: {} for name, step in self.steps\n\u001b[0m\u001b[1;32m    240\u001b[0m                             if step is not None}\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cross_accuracies = []\n",
    "\n",
    "for i in range(1,6):\n",
    "    #print(\"i:\",i)\n",
    "    for j in range(1,10):\n",
    "        #print(\"j:\",j)\n",
    "        for k in range(1,12):\n",
    "            #print(\"k:\",k)\n",
    "            for l in range(1,4):\n",
    "                if l == 1:\n",
    "                    kernel_ = \"poly\"\n",
    "                if l == 2:\n",
    "                    kernel_ = \"linear\"\n",
    "                if l == 3:\n",
    "                    kernel_ = \"rbf\"\n",
    "\n",
    "                k_ = k/3\n",
    "\n",
    "                cv_acc = []\n",
    "                for idx, item in enumerate(sets):\n",
    "                    cross_test, cross_train = item  \n",
    "\n",
    "                    cross_svm = Pipeline(((\"scaler\", StandardScaler()),\n",
    "                                         (\"svm_clf\", SVC(kernel=kernel_,\n",
    "                                                        degree=i, C=k_, gamma=100/(10**j)))))   # coef0=j\n",
    "\n",
    "                    cross_svm.fit(cross_train[:,:-1], cross_train[:,-1])\n",
    "                    cross_y_predicted = cross_svm.predict(cross_test[:,:-1])\n",
    "                    cross_y_actual = cross_test[:,-1]\n",
    "\n",
    "                    cross_accuracy = accuracy_(cross_y_actual, cross_y_predicted)\n",
    "                    cv_acc.append(cross_accuracy)\n",
    "\n",
    "\n",
    "                cross_accuracies.append([l, i, k_, 100/(10**j), np.mean(cv_acc)])\n",
    "\n",
    "    \n",
    "a = np.array(cross_accuracies)\n",
    "sorted_a = a[np.argsort(a[:, -1])]\n",
    "\n",
    "print(sorted_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the cross validation test we can see that <b>kernel=rbf</b>, <b>degree=n/a</b>, <b>C=2/3</b> and <b>gamma=0.1</b> yielded the best results for multiclass with an <b>accuracy of ~0.96</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final evaluation - Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix for prediction:\n",
      " [[46.  3.]\n",
      " [ 3. 13.]]\n",
      "\n",
      "\n",
      "Accuracy for prediction:\n",
      " 0.9076923076923077\n",
      "\n",
      "\n",
      "Metrics for classes\n",
      "_______________________________________________________________________________\n",
      "Class\t|\tPrecision\t|\tRecall\t\t|\tF1 Score\n",
      "_______________________________________________________________________________\n",
      "\n",
      "Class 1 |\t 0.939 \t\t|\t 0.939 \t\t|\t 0.939\n",
      "\n",
      "Class 2 |\t 0.812 \t\t|\t 0.812 \t\t|\t 0.812\n",
      "\n",
      "\n",
      "Weighted F1 score:\n",
      " 0.908\n",
      "\n",
      "Macro F1 score:\n",
      " 0.876\n"
     ]
    }
   ],
   "source": [
    "bi_svm = Pipeline(((\"scaler\", StandardScaler()),\n",
    "                        (\"svm_clf\", SVC(kernel=\"rbf\",\n",
    "                        degree=1, C=2/3, gamma=0.1))))\n",
    "                \n",
    "bi_svm.fit(train2[:,:-1], train2[:,-1])\n",
    "bi_y_predicted = bi_svm.predict(test2[:,:-1])\n",
    "bi_y_actual = test2[:,-1]\n",
    "        \n",
    "performance_report(bi_y_actual, bi_y_predicted, n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warm-up SVM training (without cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[:,:-1]\n",
    "y = train[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SupportVectorMachines(X,y):\n",
    "    scores = []\n",
    "    best_hyp = [0,0,0]\n",
    "    \n",
    "    for i in range(1,10):\n",
    "        C_ = i/2\n",
    "        \n",
    "        for j in range(2,6):\n",
    "            coef0_ = j\n",
    "            \n",
    "            for k in range(2,7):\n",
    "                degree_ = k\n",
    "                \n",
    "                clf = Pipeline(((\"scaler\", StandardScaler()),\n",
    "                                 (\"svm_clf\", SVC(kernel=\"poly\",\n",
    "                                                degree=degree_, coef0=coef0_, C=C_))))\n",
    "                classifier = clf.fit(X,y)\n",
    "                score = cross_val_score(classifier, X,y, cv=5, n_jobs=1).mean()\n",
    "                scores.append(score)\n",
    "\n",
    "                print(\"new iteration: \", C_, coef0_)\n",
    "                print(score, max(scores))\n",
    "\n",
    "                if score >= max(scores):\n",
    "                    best_hyp[0] = C_\n",
    "                    best_hyp[1] = coef0_\n",
    "                    best_hyp[2] = degree_\n",
    "\n",
    "    return scores, best_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, best_hyp = SupportVectorMachines(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SupportVectorMachines(X,y):\n",
    "    scores = []\n",
    "    C_list = []\n",
    "    coef_list = []\n",
    "    mapping = {}\n",
    "    \n",
    "    for i in range(1,10):\n",
    "        C_ = i/2\n",
    "        C_list.append(C_)\n",
    "        \n",
    "        for j in range(2,6):\n",
    "            coef0_ = j\n",
    "            coef_list.append(coef0_)\n",
    "                \n",
    "            clf = Pipeline(((\"scaler\", StandardScaler()),\n",
    "                             (\"svm_clf\", SVC(kernel=\"poly\",\n",
    "                                            degree=2, coef0=coef0_, C=C_))))\n",
    "            classifier = clf.fit(X,y)\n",
    "            y_predicted = clf.predict(test[:,:-1])\n",
    "\n",
    "            score = accuracy_(test[:,-1], y_predicted)\n",
    "            scores.append(score)\n",
    "        \n",
    "    return scores, C_list, coef_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, C_list, coef_list = SupportVectorMachines(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_, Y_ = np.meshgrid(C_list, coef_list)\n",
    "Z_ = X_\n",
    "for idx,i in enumerate(Z_):\n",
    "    for idx2,j in enumerate(i):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf = ax.plot_surface(X_, Y_, Z=np.array(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
