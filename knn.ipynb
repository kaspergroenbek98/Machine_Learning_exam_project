{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $k$-Nearest-Neighbors classification with Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tools import utils, prop_metrics\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import sklearn.metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = np.loadtxt('data/df_train.csv',skiprows=1,delimiter=',')\n",
    "test_raw = np.loadtxt('data/df_test.csv',skiprows=1,delimiter=',')\n",
    "\n",
    "train_features_raw = train_raw[:,:-1]\n",
    "train_labels_raw = train_raw[:,-1]\n",
    "\n",
    "test_features_raw = test_raw[:,:-1]\n",
    "test_labels_raw = test_raw[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. k-NN on vanilla data\n",
    "\n",
    "Making a baseline model on given data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data\n",
    "mean = np.mean(train_features_raw, axis=0)\n",
    "std = np.std(train_features_raw, axis=0)\n",
    "\n",
    "train_features_standardized = (train_features_raw - mean) / std\n",
    "test_features_standardized = (test_features_raw - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Create validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = utils.n_folder(5,train_features_standardized,labels=train_labels_raw,shuffle_before_split=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Train model on validation sets for different $k$ to select final hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(66.21, 4), (66.21, 1), (62.07, 3), (62.07, 2), (60.69, 8), (60.69, 5), (60.0, 6), (59.31, 7), (57.93, 10), (57.93, 9), (57.24, 12), (56.55, 14), (55.86, 17), (55.86, 11), (55.17, 16), (55.17, 13), (54.48, 18), (54.48, 15), (53.1, 20), (53.1, 19), (51.72, 21), (51.03, 26), (51.03, 25), (50.34, 24), (50.34, 23), (49.66, 28), (48.97, 27), (48.97, 22), (48.28, 30), (48.28, 29)]\n",
      "Max accuracy achieved with k = 4, at 66.21%\n"
     ]
    }
   ],
   "source": [
    "k = 30\n",
    "\n",
    "records = []\n",
    "\n",
    "for num in range(1,k+1):\n",
    "    accuracies = []\n",
    "    for item in sets:\n",
    "        test,train = item\n",
    "        \n",
    "        knn = KNeighborsClassifier(num)\n",
    "        knn.fit(train[:,:-1],train[:,-1])\n",
    "        \n",
    "        y_pred = knn.predict(test[:,:-1])\n",
    "        acc = sklearn.metrics.accuracy_score(test[:,-1], y_pred)\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    records.append((round(sum(accuracies)/len(accuracies)*100,2),num))\n",
    "print(sorted(records,reverse=True))\n",
    "print('Max accuracy achieved with k = ' + str(max(records)[1]) + ', at ' + str(max(records)[0])+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Predict on unseen data\n",
    "\n",
    "Choose below $k$ as suggested above, evaluate the printed metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix for prediction:\n",
      " [[14.  2.  1.  0.  0.  0.]\n",
      " [ 2. 17.  2.  1.  0.  0.]\n",
      " [ 5.  0.  2.  0.  0.  0.]\n",
      " [ 0.  3.  0.  3.  0.  1.]\n",
      " [ 0.  1.  0.  0.  3.  0.]\n",
      " [ 0.  0.  0.  0.  0.  8.]]\n",
      "\n",
      "\n",
      "Accuracy for prediction:\n",
      " 0.7230769230769231\n",
      "\n",
      "\n",
      "Metrics for classes\n",
      "_______________________________________________________________________________\n",
      "Class\t|\tPrecision\t|\tRecall\t\t|\tF1 Score\n",
      "_______________________________________________________________________________\n",
      "\n",
      "Class 1 |\t 0.824 \t\t|\t 0.667 \t\t|\t 0.737\n",
      "\n",
      "Class 2 |\t 0.773 \t\t|\t 0.739 \t\t|\t 0.756\n",
      "\n",
      "Class 3 |\t 0.286 \t\t|\t 0.4 \t\t|\t 0.333\n",
      "\n",
      "Class 5 |\t 0.429 \t\t|\t 0.75 \t\t|\t 0.545\n",
      "\n",
      "Class 6 |\t 0.75 \t\t|\t 1.0 \t\t|\t 0.857\n",
      "\n",
      "Class 7 |\t 1.0 \t\t|\t 0.889 \t\t|\t 0.941\n",
      "\n",
      "\n",
      "Weighted F1 score:\n",
      " 0.734\n",
      "\n",
      "Macro F1 score:\n",
      " 0.695\n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "\n",
    "n_classes = 6\n",
    "\n",
    "knn = KNeighborsClassifier(k)\n",
    "\n",
    "knn.fit(train_features_standardized,train_labels_raw)\n",
    "\n",
    "y_pred = knn.predict(test_features_standardized)\n",
    "\n",
    "\n",
    "prop_metrics.performance_report(test_labels_raw, y_pred, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. k-NN with principal components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Decompose data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = sklearn.decomposition.PCA()\n",
    "\n",
    "pca_train_features = pca.fit_transform(train_features_standardized)\n",
    "pca_test_features = pca.transform(test_features_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_var = 0\n",
    "\n",
    "#for num in range(len(pca.explained_variance_ratio_)):\n",
    " #   print('('+str(num+1)+','+str(round(pca.explained_variance_ratio_[num],3))+')')\n",
    "\n",
    "#for num in range(len(pca.explained_variance_ratio_)):\n",
    " #   cumulative_var += pca.explained_variance_ratio_[num]\n",
    "  #  print('(',num+1,',',round(cumulative_var,3),')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 5-component model for ensemble method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = utils.n_folder(5,pca_train_features[:,:5],labels=train_labels_raw,shuffle_before_split=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Train model on validation sets for different $k$ to select final hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(67.59, 1), (66.21, 4), (64.83, 6), (64.14, 5), (64.14, 2), (63.45, 7), (63.45, 3), (62.76, 8), (61.38, 10), (61.38, 9), (58.62, 15), (58.62, 12), (57.24, 11), (56.55, 16), (56.55, 14), (56.55, 13), (54.48, 17), (53.79, 23), (53.79, 22), (53.79, 21), (53.1, 20), (53.1, 19), (52.41, 24), (51.72, 27), (51.72, 18), (51.03, 28), (51.03, 25), (50.34, 26), (49.66, 30), (48.97, 29)]\n",
      "Max accuracy achieved with k = 1, at 67.59%\n"
     ]
    }
   ],
   "source": [
    "k = 30\n",
    "\n",
    "records = []\n",
    "\n",
    "for num in range(1,k+1):\n",
    "    accuracies = []\n",
    "    for item in sets:\n",
    "        test,train = item\n",
    "        \n",
    "        knn = KNeighborsClassifier(num)\n",
    "        knn.fit(train[:,:-1],train[:,-1])\n",
    "        \n",
    "        y_pred = knn.predict(test[:,:-1])\n",
    "        acc = sklearn.metrics.accuracy_score(test[:,-1], y_pred)\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    records.append((round(sum(accuracies)/len(accuracies)*100,2),num))\n",
    "print(sorted(records,reverse=True))\n",
    "print('Max accuracy achieved with k = ' + str(max(records)[1]) + ', at ' + str(max(records)[0])+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Predict on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix for prediction:\n",
      " [[15.  1.  1.  0.  0.  0.]\n",
      " [ 2. 17.  3.  1.  0.  0.]\n",
      " [ 4.  1.  1.  0.  0.  0.]\n",
      " [ 0.  3.  0.  3.  0.  1.]\n",
      " [ 0.  1.  0.  0.  3.  1.]\n",
      " [ 0.  0.  0.  0.  0.  7.]]\n",
      "\n",
      "\n",
      "Accuracy for prediction:\n",
      " 0.7076923076923077\n",
      "\n",
      "\n",
      "Metrics for classes\n",
      "_______________________________________________________________________________\n",
      "Class\t|\tPrecision\t|\tRecall\t\t|\tF1 Score\n",
      "_______________________________________________________________________________\n",
      "\n",
      "Class 1 |\t 0.882 \t\t|\t 0.714 \t\t|\t 0.789\n",
      "\n",
      "Class 2 |\t 0.739 \t\t|\t 0.739 \t\t|\t 0.739\n",
      "\n",
      "Class 3 |\t 0.167 \t\t|\t 0.2 \t\t|\t 0.182\n",
      "\n",
      "Class 5 |\t 0.429 \t\t|\t 0.75 \t\t|\t 0.545\n",
      "\n",
      "Class 6 |\t 0.6 \t\t|\t 1.0 \t\t|\t 0.75\n",
      "\n",
      "Class 7 |\t 1.0 \t\t|\t 0.778 \t\t|\t 0.875\n",
      "\n",
      "\n",
      "Weighted F1 score:\n",
      " 0.72\n",
      "\n",
      "Macro F1 score:\n",
      " 0.647\n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "\n",
    "n_classes = 6\n",
    "\n",
    "knn = KNeighborsClassifier(k)\n",
    "\n",
    "knn.fit(pca_train_features[:,:5],train_labels_raw)\n",
    "\n",
    "y_pred = knn.predict(pca_test_features[:,:5])\n",
    "\n",
    "\n",
    "prop_metrics.performance_report(test_labels_raw, y_pred, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 2-component model to compare with LD-components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = utils.n_folder(5,pca_train_features[:,:2],labels=train_labels_raw,shuffle_before_split=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Train model on validation sets for different $k$ to select final hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(60.0, 9), (60.0, 8), (60.0, 7), (60.0, 4), (59.31, 17), (59.31, 10), (59.31, 6), (58.62, 19), (58.62, 15), (58.62, 11), (57.93, 14), (57.93, 13), (57.93, 12), (57.93, 5), (57.24, 22), (57.24, 21), (57.24, 18), (57.24, 16), (57.24, 3), (55.86, 23), (55.86, 20), (55.86, 2), (55.17, 30), (55.17, 26), (54.48, 29), (54.48, 28), (54.48, 27), (54.48, 25), (54.48, 24), (51.03, 1)]\n",
      "Max accuracy achieved with k = 9, at 60.0%\n"
     ]
    }
   ],
   "source": [
    "k = 30\n",
    "\n",
    "records = []\n",
    "\n",
    "for num in range(1,k+1):\n",
    "    accuracies = []\n",
    "    for item in sets:\n",
    "        test,train = item\n",
    "        \n",
    "        knn = KNeighborsClassifier(num)\n",
    "        knn.fit(train[:,:-1],train[:,-1])\n",
    "        \n",
    "        y_pred = knn.predict(test[:,:-1])\n",
    "        acc = sklearn.metrics.accuracy_score(test[:,-1], y_pred)\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    records.append((round(sum(accuracies)/len(accuracies)*100,2),num))\n",
    "\n",
    "print(sorted(records,reverse=True))\n",
    "print('Max accuracy achieved with k = ' + str(max(records)[1]) + ', at ' + str(max(records)[0])+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Predict on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix for prediction:\n",
      " [[18.  4.  2.  1.  0.  0.]\n",
      " [ 3. 18.  3.  1.  1.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  2.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  8.]]\n",
      "\n",
      "\n",
      "Accuracy for prediction:\n",
      " 0.676923076923077\n",
      "\n",
      "\n",
      "Metrics for classes\n",
      "_______________________________________________________________________________\n",
      "Class\t|\tPrecision\t|\tRecall\t\t|\tF1 Score\n",
      "_______________________________________________________________________________\n",
      "\n",
      "Class 1 |\t 0.72 \t\t|\t 0.857 \t\t|\t 0.783\n",
      "\n",
      "Class 2 |\t 0.667 \t\t|\t 0.783 \t\t|\t 0.72\n",
      "\n",
      "Class 3 |\t 0 \t\t|\t 0.0 \t\t|\t 0\n",
      "\n",
      "Class 5 |\t 0.0 \t\t|\t 0.0 \t\t|\t 0\n",
      "\n",
      "Class 6 |\t 0.0 \t\t|\t 0.0 \t\t|\t 0\n",
      "\n",
      "Class 7 |\t 0.889 \t\t|\t 0.889 \t\t|\t 0.889\n",
      "\n",
      "\n",
      "Weighted F1 score:\n",
      " 0.631\n",
      "\n",
      "Macro F1 score:\n",
      " 0.399\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "\n",
    "n_classes = 6\n",
    "\n",
    "knn = KNeighborsClassifier(k)\n",
    "\n",
    "knn.fit(pca_train_features[:,:2],train_labels_raw)\n",
    "\n",
    "y_pred = knn.predict(pca_test_features[:,:2])\n",
    "\n",
    "\n",
    "prop_metrics.performance_report(test_labels_raw, y_pred, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. k-NN with LD components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Decompose data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis(solver='eigen')\n",
    "\n",
    "lda_train_features = lda.fit_transform(train_features_standardized,train_labels_raw)\n",
    "lda_test_features = lda.transform(test_features_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_plot_data = np.column_stack((lda_train_features[:,:2],train_labels_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {1: 'a', 2: 'b', 3: 'c', 5: 'd', 6: 'e', 7: 'f'}\n",
    "\n",
    "#for item in lda_plot_data:\n",
    " #   print(str(round(item[0],3)) + ' ' + str(round(item[1],3)) + ' ' + classes[item[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cumulative_var = 0\n",
    "\n",
    "#for num in range(len(lda.explained_variance_ratio_)):\n",
    " #   print('(' + str(num+1) + ',' + str(round(lda.explained_variance_ratio_[num],3)) + ')')\n",
    "\n",
    "#for num in range(len(lda.explained_variance_ratio_)):\n",
    " #   cumulative_var += lda.explained_variance_ratio_[num]\n",
    "  #  print('(' + str(num+1) + ',' + str(round(cumulative_var,3)) +')')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Create validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = utils.n_folder(5,lda_train_features[:,:2],labels=train_labels_raw,shuffle_before_split=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Train model on validation sets for different $k$ to select final hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[59.31, 57.77, 5], [59.31, 56.67, 8], [58.62, 56.65, 4], [57.93, 54.56, 9], [57.24, 54.93, 3], [56.55, 53.11, 11], [56.55, 52.84, 10], [56.55, 52.56, 13], [55.86, 52.47, 25], [55.86, 52.29, 27], [55.86, 52.06, 17], [55.86, 51.94, 12], [55.86, 51.87, 15], [55.86, 51.78, 2], [55.86, 51.74, 14], [55.17, 53.38, 6], [55.17, 53.2, 7], [55.17, 51.32, 23], [55.17, 50.79, 29], [54.48, 52.4, 1], [54.48, 51.27, 19], [54.48, 51.11, 21], [54.48, 51.09, 22], [54.48, 51.0, 20], [54.48, 50.72, 24], [54.48, 50.47, 28], [54.48, 50.43, 16], [53.79, 49.29, 30], [53.1, 49.71, 26], [53.1, 49.09, 18]]\n",
      "Max accuracy achieved with k = 5, at 59.31%\n"
     ]
    }
   ],
   "source": [
    "k = 30\n",
    "\n",
    "records = []\n",
    "\n",
    "for num in range(1,k+1):\n",
    "    accuracies = []\n",
    "    wf1s = []\n",
    "    for item in sets:\n",
    "        test,train = item\n",
    "        \n",
    "        knn = KNeighborsClassifier(num)\n",
    "        knn.fit(train[:,:-1],train[:,-1])\n",
    "        \n",
    "        y_pred = knn.predict(test[:,:-1])\n",
    "        acc = sklearn.metrics.accuracy_score(test[:,-1], y_pred)\n",
    "        accuracies.append(acc)\n",
    "        \n",
    "        weighted_f1 = sklearn.metrics.f1_score(test[:,-1],y_pred,average='weighted')\n",
    "        wf1s.append(weighted_f1)\n",
    "\n",
    "    avg_wf1 = round(sum(wf1s)/len(wf1s)*100,2)\n",
    "    records.append([round(sum(accuracies)/len(accuracies)*100,2),avg_wf1,num])\n",
    "print(sorted(records,reverse=True))\n",
    "print('Max accuracy achieved with k = ' + str(max(records)[2]) + ', at ' + str(max(records)[0])+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Plot decision boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_data = False\n",
    "\n",
    "if create_data:\n",
    "\n",
    "    db_X = np.loadtxt('data/db_data.csv',delimiter=',')\n",
    "\n",
    "\n",
    "    k = 4\n",
    "\n",
    "    knn = KNeighborsClassifier(k)\n",
    "\n",
    "    knn.fit(lda_train_features[:,:2],train_labels_raw)\n",
    "\n",
    "    y_pred = knn.predict(db_X)\n",
    "\n",
    "    labels_interpreted = np.array([classes[i] for i in y_pred])\n",
    "    outfile = np.column_stack((db_X,labels_interpreted))\n",
    "    \n",
    "    lines = []\n",
    "\n",
    "    for row in outfile:\n",
    "        lines.append(' '.join([str(row[0]),str(row[1]),str(row[2])]))\n",
    "\n",
    "    f = open(\"db_coords.txt\", \"w\")\n",
    "    f.write('\\n'.join(lines))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Predict on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix for prediction:\n",
      " [[17. 10.  2.  0.  1.  0.]\n",
      " [ 2. 10.  3.  1.  0.  0.]\n",
      " [ 2.  1.  0.  0.  0.  0.]\n",
      " [ 0.  2.  0.  3.  0.  1.]\n",
      " [ 0.  0.  0.  0.  2.  1.]\n",
      " [ 0.  0.  0.  0.  0.  7.]]\n",
      "\n",
      "\n",
      "Accuracy for prediction:\n",
      " 0.6\n",
      "\n",
      "\n",
      "Metrics for classes\n",
      "_______________________________________________________________________________\n",
      "Class\t|\tPrecision\t|\tRecall\t\t|\tF1 Score\n",
      "_______________________________________________________________________________\n",
      "\n",
      "Class 1 |\t 0.567 \t\t|\t 0.81 \t\t|\t 0.667\n",
      "\n",
      "Class 2 |\t 0.625 \t\t|\t 0.435 \t\t|\t 0.513\n",
      "\n",
      "Class 3 |\t 0.0 \t\t|\t 0.0 \t\t|\t 0\n",
      "\n",
      "Class 5 |\t 0.5 \t\t|\t 0.75 \t\t|\t 0.6\n",
      "\n",
      "Class 6 |\t 0.667 \t\t|\t 0.667 \t\t|\t 0.667\n",
      "\n",
      "Class 7 |\t 1.0 \t\t|\t 0.778 \t\t|\t 0.875\n",
      "\n",
      "\n",
      "Weighted F1 score:\n",
      " 0.586\n",
      "\n",
      "Macro F1 score:\n",
      " 0.554\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "\n",
    "n_classes = 6\n",
    "\n",
    "knn = KNeighborsClassifier(k)\n",
    "\n",
    "knn.fit(lda_train_features[:,:2],train_labels_raw)\n",
    "\n",
    "y_pred = knn.predict(lda_test_features[:,:2])\n",
    "\n",
    "prop_metrics.performance_report(test_labels_raw, y_pred, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 score\n",
      " 0.5856903353057199\n"
     ]
    }
   ],
   "source": [
    "# to compute weighted F1\n",
    "\n",
    "weighted_f1 = sklearn.metrics.f1_score(test_labels_raw,y_pred,average='weighted')\n",
    "\n",
    "print(\"Weighted F1 score\\n\",weighted_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 score\n",
      " 0.6\n"
     ]
    }
   ],
   "source": [
    "# to compute micro F1\n",
    "\n",
    "micro_f1 = sklearn.metrics.f1_score(test_labels_raw,y_pred,average='micro')\n",
    "\n",
    "print(\"Micro F1 score\\n\",micro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes = {1: 'aa', 2: 'bb', 3: 'cc', 5: 'dd', 6: 'ee', 7: 'ff'}\n",
    "\n",
    "#dat = np.column_stack((lda_test_features[:,:2],test_labels_raw))\n",
    "\n",
    "#for row in dat:\n",
    " #   print(round(row[0],3),round(row[1],3),classes[row[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Binary classification with LD-components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Reclassify labels into window/non-window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_raw[train_labels_raw < 4] = 1\n",
    "train_labels_raw[train_labels_raw > 4] = 2\n",
    "\n",
    "test_labels_raw[test_labels_raw < 4] = 1\n",
    "test_labels_raw[test_labels_raw > 4] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Create validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = utils.n_folder(5,lda_train_features[:,:2],labels=train_labels_raw,shuffle_before_split=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Train model on validation sets for different  $k$ to select final hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(95.86, 1), (94.48, 15), (93.79, 17), (93.79, 16), (93.79, 14), (93.79, 13), (93.1, 23), (93.1, 21), (93.1, 19), (93.1, 18), (93.1, 12), (93.1, 11), (93.1, 9), (93.1, 8), (92.41, 30), (92.41, 27), (92.41, 26), (92.41, 25), (92.41, 24), (92.41, 22), (92.41, 20), (92.41, 10), (92.41, 4), (92.41, 3), (91.72, 29), (91.72, 28), (91.72, 7), (91.72, 5), (91.03, 6), (91.03, 2)]\n",
      "Max accuracy achieved with k = 1, at 95.86%\n"
     ]
    }
   ],
   "source": [
    "k = 30\n",
    "\n",
    "records = []\n",
    "\n",
    "for num in range(1,k+1):\n",
    "    accuracies = []\n",
    "    for item in sets:\n",
    "        test,train = item\n",
    "        \n",
    "        knn = KNeighborsClassifier(num)\n",
    "        knn.fit(train[:,:-1],train[:,-1])\n",
    "        \n",
    "        y_pred = knn.predict(test[:,:-1])\n",
    "        acc = sklearn.metrics.accuracy_score(test[:,-1], y_pred)\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    records.append((round(sum(accuracies)/len(accuracies)*100,2),num))\n",
    "print(sorted(records,reverse=True))\n",
    "print('Max accuracy achieved with k = ' + str(max(records)[1]) + ', at ' + str(max(records)[0])+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Predict on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix for prediction:\n",
      " [[44.  2.]\n",
      " [ 5. 14.]]\n",
      "\n",
      "\n",
      "Accuracy for prediction:\n",
      " 0.8923076923076924\n",
      "\n",
      "\n",
      "Metrics for classes\n",
      "_______________________________________________________________________________\n",
      "Class\t|\tPrecision\t|\tRecall\t\t|\tF1 Score\n",
      "_______________________________________________________________________________\n",
      "\n",
      "Class 1 |\t 0.957 \t\t|\t 0.898 \t\t|\t 0.926\n",
      "\n",
      "Class 2 |\t 0.737 \t\t|\t 0.875 \t\t|\t 0.8\n",
      "\n",
      "\n",
      "Weighted F1 score:\n",
      " 0.895\n",
      "\n",
      "Macro F1 score:\n",
      " 0.863\n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "\n",
    "n_classes = 2\n",
    "\n",
    "knn = KNeighborsClassifier(k)\n",
    "\n",
    "knn.fit(lda_train_features[:,:2],train_labels_raw)\n",
    "\n",
    "y_pred = knn.predict(lda_test_features[:,:2])\n",
    "\n",
    "\n",
    "prop_metrics.performance_report(test_labels_raw, y_pred, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 score\n",
      " 0.8952226720647773\n"
     ]
    }
   ],
   "source": [
    "# to compute weighted F1\n",
    "\n",
    "weighted_f1 = sklearn.metrics.f1_score(test_labels_raw,y_pred,average='weighted')\n",
    "\n",
    "print(\"Weighted F1 score\\n\",weighted_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 score\n",
      " 0.8923076923076924\n"
     ]
    }
   ],
   "source": [
    "micro_f1 = sklearn.metrics.f1_score(test_labels_raw,y_pred,average='micro')\n",
    "\n",
    "print(\"Micro F1 score\\n\",micro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
